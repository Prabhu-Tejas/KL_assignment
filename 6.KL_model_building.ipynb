{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data management, data visualisation libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"KL_encoded_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'Furnishing_Fully Furnished', 'Furnishing_Partly Furnished',\n",
       "       'Furnishing_Unfurnished', 'Furnishing_Unknown', 'area_Ampang',\n",
       "       'area_Ampang Hilir', 'area_Bandar Damai Perdana',\n",
       "       'area_Bandar Menjalara', 'area_Bandar Tasik Selatan',\n",
       "       ...\n",
       "       'Property Type Supergroup_Serviced Residence',\n",
       "       'Property Type Supergroup_Terrace/Link House',\n",
       "       'Property Type Supergroup_Townhouse', 'Bathrooms', 'Car Parks', 'size',\n",
       "       'No_of_Bedrooms', 'No_of_servant_rooms', 'studio_apartment', 'Price'],\n",
       "      dtype='object', length=101)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>Furnishing_Fully Furnished</th>\n",
       "      <th>Furnishing_Partly Furnished</th>\n",
       "      <th>Furnishing_Unfurnished</th>\n",
       "      <th>Furnishing_Unknown</th>\n",
       "      <th>area_Ampang</th>\n",
       "      <th>area_Ampang Hilir</th>\n",
       "      <th>area_Bandar Damai Perdana</th>\n",
       "      <th>area_Bandar Menjalara</th>\n",
       "      <th>area_Bandar Tasik Selatan</th>\n",
       "      <th>...</th>\n",
       "      <th>Property Type Supergroup_Serviced Residence</th>\n",
       "      <th>Property Type Supergroup_Terrace/Link House</th>\n",
       "      <th>Property Type Supergroup_Townhouse</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Car Parks</th>\n",
       "      <th>size</th>\n",
       "      <th>No_of_Bedrooms</th>\n",
       "      <th>No_of_servant_rooms</th>\n",
       "      <th>studio_apartment</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023213</td>\n",
       "      <td>-0.024893</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>-0.903351</td>\n",
       "      <td>1.034760</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>1250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667647</td>\n",
       "      <td>-0.024893</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>-0.109230</td>\n",
       "      <td>-0.786458</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>1030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023213</td>\n",
       "      <td>-0.024893</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>0.684891</td>\n",
       "      <td>1.034760</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.312081</td>\n",
       "      <td>1.470644</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>0.684891</td>\n",
       "      <td>2.855978</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>5350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667647</td>\n",
       "      <td>1.470644</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>1.479012</td>\n",
       "      <td>-0.786458</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>2600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28923</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621221</td>\n",
       "      <td>-0.772661</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>-0.109230</td>\n",
       "      <td>-0.786458</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28924</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023213</td>\n",
       "      <td>-0.024893</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>-0.109230</td>\n",
       "      <td>1.034760</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>1400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28925</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.265655</td>\n",
       "      <td>-0.772661</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>-1.697473</td>\n",
       "      <td>-0.786458</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28926</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.956515</td>\n",
       "      <td>0.722876</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>0.684891</td>\n",
       "      <td>2.855978</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>2700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28927</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621221</td>\n",
       "      <td>0.722876</td>\n",
       "      <td>-0.00588</td>\n",
       "      <td>0.684891</td>\n",
       "      <td>-0.786458</td>\n",
       "      <td>-0.104417</td>\n",
       "      <td>540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28928 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type  Furnishing_Fully Furnished  Furnishing_Partly Furnished  \\\n",
       "0         0                         1.0                          0.0   \n",
       "1         0                         0.0                          1.0   \n",
       "2         0                         0.0                          1.0   \n",
       "3         1                         0.0                          1.0   \n",
       "4         1                         0.0                          1.0   \n",
       "...     ...                         ...                          ...   \n",
       "28923     0                         0.0                          1.0   \n",
       "28924     1                         1.0                          0.0   \n",
       "28925     0                         0.0                          1.0   \n",
       "28926     0                         0.0                          1.0   \n",
       "28927     0                         0.0                          1.0   \n",
       "\n",
       "       Furnishing_Unfurnished  Furnishing_Unknown  area_Ampang  \\\n",
       "0                         0.0                 0.0          0.0   \n",
       "1                         0.0                 0.0          0.0   \n",
       "2                         0.0                 0.0          0.0   \n",
       "3                         0.0                 0.0          0.0   \n",
       "4                         0.0                 0.0          0.0   \n",
       "...                       ...                 ...          ...   \n",
       "28923                     0.0                 0.0          0.0   \n",
       "28924                     0.0                 0.0          0.0   \n",
       "28925                     0.0                 0.0          0.0   \n",
       "28926                     0.0                 0.0          0.0   \n",
       "28927                     0.0                 0.0          0.0   \n",
       "\n",
       "       area_Ampang Hilir  area_Bandar Damai Perdana  area_Bandar Menjalara  \\\n",
       "0                    0.0                        0.0                    0.0   \n",
       "1                    0.0                        0.0                    0.0   \n",
       "2                    0.0                        0.0                    0.0   \n",
       "3                    0.0                        0.0                    0.0   \n",
       "4                    0.0                        0.0                    0.0   \n",
       "...                  ...                        ...                    ...   \n",
       "28923                0.0                        0.0                    0.0   \n",
       "28924                0.0                        0.0                    0.0   \n",
       "28925                0.0                        0.0                    0.0   \n",
       "28926                0.0                        0.0                    0.0   \n",
       "28927                0.0                        0.0                    0.0   \n",
       "\n",
       "       area_Bandar Tasik Selatan  ...  \\\n",
       "0                            0.0  ...   \n",
       "1                            0.0  ...   \n",
       "2                            0.0  ...   \n",
       "3                            0.0  ...   \n",
       "4                            0.0  ...   \n",
       "...                          ...  ...   \n",
       "28923                        0.0  ...   \n",
       "28924                        0.0  ...   \n",
       "28925                        0.0  ...   \n",
       "28926                        0.0  ...   \n",
       "28927                        0.0  ...   \n",
       "\n",
       "       Property Type Supergroup_Serviced Residence  \\\n",
       "0                                              1.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "28923                                          0.0   \n",
       "28924                                          0.0   \n",
       "28925                                          0.0   \n",
       "28926                                          0.0   \n",
       "28927                                          0.0   \n",
       "\n",
       "       Property Type Supergroup_Terrace/Link House  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "28923                                          0.0   \n",
       "28924                                          0.0   \n",
       "28925                                          0.0   \n",
       "28926                                          0.0   \n",
       "28927                                          0.0   \n",
       "\n",
       "       Property Type Supergroup_Townhouse  Bathrooms  Car Parks     size  \\\n",
       "0                                     0.0   0.023213  -0.024893 -0.00588   \n",
       "1                                     0.0   0.667647  -0.024893 -0.00588   \n",
       "2                                     0.0   0.023213  -0.024893 -0.00588   \n",
       "3                                     0.0   1.312081   1.470644 -0.00588   \n",
       "4                                     0.0   0.667647   1.470644 -0.00588   \n",
       "...                                   ...        ...        ...      ...   \n",
       "28923                                 0.0  -0.621221  -0.772661 -0.00588   \n",
       "28924                                 0.0   0.023213  -0.024893 -0.00588   \n",
       "28925                                 0.0  -1.265655  -0.772661 -0.00588   \n",
       "28926                                 0.0   1.956515   0.722876 -0.00588   \n",
       "28927                                 0.0  -0.621221   0.722876 -0.00588   \n",
       "\n",
       "       No_of_Bedrooms  No_of_servant_rooms  studio_apartment    Price  \n",
       "0           -0.903351             1.034760         -0.104417  1250000  \n",
       "1           -0.109230            -0.786458         -0.104417  1030000  \n",
       "2            0.684891             1.034760         -0.104417   900000  \n",
       "3            0.684891             2.855978         -0.104417  5350000  \n",
       "4            1.479012            -0.786458         -0.104417  2600000  \n",
       "...               ...                  ...               ...      ...  \n",
       "28923       -0.109230            -0.786458         -0.104417   750000  \n",
       "28924       -0.109230             1.034760         -0.104417  1400000  \n",
       "28925       -1.697473            -0.786458         -0.104417   880000  \n",
       "28926        0.684891             2.855978         -0.104417  2700000  \n",
       "28927        0.684891            -0.786458         -0.104417   540000  \n",
       "\n",
       "[28928 rows x 101 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.597763297052185e+30, 2756404051849471.5, -1.6049116701245396e+18)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Separating the target variable (Price) from the features\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing and training the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, rmse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 7.597763297052185e+30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+16, tolerance: 1.265e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression MSE: 1803719585980.8127\n",
      "Ridge Regression MSE: 1793559902956.6907\n",
      "Elastic Net Regression MSE: 1973275459278.5393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "linear_pred = linear_model.predict(X_test)\n",
    "linear_mse = mean_squared_error(y_test, linear_pred)\n",
    "print(\"Linear Regression MSE:\", linear_mse)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.1)  # Adjust alpha as needed\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "print(\"Lasso Regression MSE:\", lasso_mse)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)  # Adjust alpha as needed\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "print(\"Ridge Regression MSE:\", ridge_mse)\n",
    "\n",
    "# Elastic Net Regression\n",
    "elastic_net_model = ElasticNet(alpha=0.1, l1_ratio=0.5)  # Adjust alpha and l1_ratio as needed\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "elastic_net_pred = elastic_net_model.predict(X_test)\n",
    "elastic_net_mse = mean_squared_error(y_test, elastic_net_pred)\n",
    "print(\"Elastic Net Regression MSE:\", elastic_net_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "MSE: 7.597763297052185e+30\n",
      "RMSE: 2756404051849471.5\n",
      "MAE: 64384098632570.09\n",
      "R-squared: -1.6049116701245396e+18\n",
      "\n",
      "Lasso Regression:\n",
      "MSE: 1803719585980.8127\n",
      "RMSE: 1343026.278961366\n",
      "MAE: 607767.9956661524\n",
      "R-squared: 0.6189917348049062\n",
      "\n",
      "Ridge Regression:\n",
      "MSE: 1793559902956.6907\n",
      "RMSE: 1339238.55341634\n",
      "MAE: 606959.0200057392\n",
      "R-squared: 0.6211378129614218\n",
      "\n",
      "Elastic Net Regression:\n",
      "MSE: 1973275459278.5393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate metrics for Linear Regression\n",
    "linear_mse = mean_squared_error(y_test, linear_pred)\n",
    "linear_rmse = mean_squared_error(y_test, linear_pred, squared=False)  # RMSE\n",
    "linear_mae = mean_absolute_error(y_test, linear_pred)  # MAE\n",
    "linear_r2 = r2_score(y_test, linear_pred)  # R-squared\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(\"MSE:\", linear_mse)\n",
    "print(\"RMSE:\", linear_rmse)\n",
    "print(\"MAE:\", linear_mae)\n",
    "print(\"R-squared:\", linear_r2)\n",
    "print()\n",
    "\n",
    "# Calculate metrics for Lasso Regression\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "lasso_rmse = mean_squared_error(y_test, lasso_pred, squared=False)  # RMSE\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_pred)  # MAE\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)  # R-squared\n",
    "\n",
    "print(\"Lasso Regression:\")\n",
    "print(\"MSE:\", lasso_mse)\n",
    "print(\"RMSE:\", lasso_rmse)\n",
    "print(\"MAE:\", lasso_mae)\n",
    "print(\"R-squared:\", lasso_r2)\n",
    "print()\n",
    "\n",
    "# Calculate metrics for Ridge Regression\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "ridge_rmse = mean_squared_error(y_test, ridge_pred, squared=False)  # RMSE\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)  # MAE\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)  # R-squared\n",
    "\n",
    "print(\"Ridge Regression:\")\n",
    "print(\"MSE:\", ridge_mse)\n",
    "print(\"RMSE:\", ridge_rmse)\n",
    "print(\"MAE:\", ridge_mae)\n",
    "print(\"R-squared:\", ridge_r2)\n",
    "print()\n",
    "\n",
    "# Calculate metrics for Elastic Net Regression\n",
    "elastic_net_mse = mean_squared_error(y_test, elastic_net_pred)\n",
    "elastic_net_rmse = mean_squared_error(y_test, elastic_net_pred, squared=False)  # RMSE\n",
    "elastic_net_mae = mean_absolute_error(y_test, elastic_net_pred)  # MAE\n",
    "elastic_net_r2 = r2_score(y_test, elastic_net_pred)  # R-squared\n",
    "\n",
    "print(\"Elastic Net Regression:\")\n",
    "print(\"MSE:\", elastic_net_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324236.0409297652, 0.629578502591402, 1262481.3266184793, 0.6633215631745824)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Ridge Regression with Cross-Validation\n",
    "ridge_cv = RidgeCV(alphas=[0.1, 1.0, 10.0, 100.0], cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "ridge_pred = ridge_cv.predict(X_test)\n",
    "ridge_rmse = mean_squared_error(y_test, ridge_pred, squared=False)\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "\n",
    "# Gradient Boosting Regressor with default parameters as a starting point\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr_pred = gbr.predict(X_test)\n",
    "gbr_rmse = mean_squared_error(y_test, gbr_pred, squared=False)\n",
    "gbr_r2 = r2_score(y_test, gbr_pred)\n",
    "\n",
    "ridge_rmse, ridge_r2, gbr_rmse, gbr_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.407e+15, tolerance: 1.064e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+15, tolerance: 8.732e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e+15, tolerance: 1.047e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+15, tolerance: 1.024e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+15, tolerance: 1.053e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.407e+15, tolerance: 1.064e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+15, tolerance: 8.732e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e+15, tolerance: 1.047e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+15, tolerance: 1.024e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+15, tolerance: 1.053e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.407e+15, tolerance: 1.064e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+15, tolerance: 8.732e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+15, tolerance: 1.047e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+15, tolerance: 1.024e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+15, tolerance: 1.053e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e+15, tolerance: 1.064e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+15, tolerance: 8.732e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+15, tolerance: 1.047e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e+15, tolerance: 1.024e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.355e+15, tolerance: 1.053e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.814e+15, tolerance: 1.265e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+15, tolerance: 1.064e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.488e+14, tolerance: 8.732e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.827e+14, tolerance: 1.047e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+15, tolerance: 1.024e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.025e+14, tolerance: 1.053e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+16, tolerance: 1.064e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+16, tolerance: 8.732e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+16, tolerance: 1.047e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+16, tolerance: 1.024e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+16, tolerance: 1.053e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e+16, tolerance: 1.064e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+16, tolerance: 8.732e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.254e+16, tolerance: 1.047e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+16, tolerance: 1.024e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+16, tolerance: 1.053e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e+16, tolerance: 1.064e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.476e+16, tolerance: 8.732e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e+16, tolerance: 1.047e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+16, tolerance: 1.024e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e+16, tolerance: 1.053e+13\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m lasso_grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     50\u001b[0m ridge_grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 51\u001b[0m elastic_net_grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Best parameters for each model\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for Linear Regression:\u001b[39m\u001b[38;5;124m\"\u001b[39m, linear_grid\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 420\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:905\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[0;32m    904\u001b[0m     X_copied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept\n\u001b[1;32m--> 905\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    906\u001b[0m         X,\n\u001b[0;32m    907\u001b[0m         y,\n\u001b[0;32m    908\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    909\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    910\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[0;32m    911\u001b[0m         copy\u001b[38;5;241m=\u001b[39mX_copied,\n\u001b[0;32m    912\u001b[0m         multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    913\u001b[0m         y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    914\u001b[0m     )\n\u001b[0;32m    915\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    916\u001b[0m         y, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    919\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 120\u001b[0m     first_pass_isfinite \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39misfinite(xp\u001b[38;5;241m.\u001b[39msum(X))\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2324\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   2322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m-> 2324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39madd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, dtype, out, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   2325\u001b[0m                       initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[1;32mc:\\Users\\prabh\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define X and y (assuming they are defined previously)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline for Linear Regression\n",
    "linear_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "# Pipeline for Lasso Regression\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso())\n",
    "])\n",
    "\n",
    "# Pipeline for Ridge Regression\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "# Pipeline for Elastic Net Regression\n",
    "elastic_net_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('elastic_net', ElasticNet())\n",
    "])\n",
    "\n",
    "# Define hyperparameters grid for each model\n",
    "linear_params = {}\n",
    "lasso_params = {'lasso__alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "ridge_params = {'ridge__alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "elastic_net_params = {'elastic_net__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "                     'elastic_net__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]}\n",
    "\n",
    "# GridSearchCV with cross-validation\n",
    "linear_grid = GridSearchCV(linear_pipeline, param_grid=linear_params, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_grid = GridSearchCV(lasso_pipeline, param_grid=lasso_params, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_grid = GridSearchCV(ridge_pipeline, param_grid=ridge_params, cv=5, scoring='neg_mean_squared_error')\n",
    "elastic_net_grid = GridSearchCV(elastic_net_pipeline, param_grid=elastic_net_params, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the models\n",
    "linear_grid.fit(X_train, y_train)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "elastic_net_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters for each model\n",
    "print(\"Best parameters for Linear Regression:\", linear_grid.best_params_)\n",
    "print(\"Best parameters for Lasso Regression:\", lasso_grid.best_params_)\n",
    "print(\"Best parameters for Ridge Regression:\", ridge_grid.best_params_)\n",
    "print(\"Best parameters for Elastic Net Regression:\", elastic_net_grid.best_params_)\n",
    "\n",
    "# Predictions and evaluation\n",
    "linear_pred = linear_grid.predict(X_test)\n",
    "lasso_pred = lasso_grid.predict(X_test)\n",
    "ridge_pred = ridge_grid.predict(X_test)\n",
    "elastic_net_pred = elastic_net_grid.predict(X_test)\n",
    "\n",
    "linear_mse = mean_squared_error(y_test, linear_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "elastic_net_mse = mean_squared_error(y_test, elastic_net_pred)\n",
    "\n",
    "print(\"Linear Regression MSE:\", linear_mse)\n",
    "print(\"Lasso Regression MSE:\", lasso_mse)\n",
    "print(\"Ridge Regression MSE:\", ridge_mse)\n",
    "print(\"Elastic Net Regression MSE:\", elastic_net_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Fit the models\n",
    "linear_grid.fit(X_train, y_train)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "elastic_net_grid.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "linear_train_pred = linear_grid.predict(X_train)\n",
    "lasso_train_pred = lasso_grid.predict(X_train)\n",
    "ridge_train_pred = ridge_grid.predict(X_train)\n",
    "elastic_net_train_pred = elastic_net_grid.predict(X_train)\n",
    "\n",
    "# Train evaluation\n",
    "print(\"Train Evaluation Metrics:\")\n",
    "print(\"Linear Regression MAE:\", mean_absolute_error(y_train, linear_train_pred))\n",
    "print(\"Lasso Regression MAE:\", mean_absolute_error(y_train, lasso_train_pred))\n",
    "print(\"Ridge Regression MAE:\", mean_absolute_error(y_train, ridge_train_pred))\n",
    "print(\"Elastic Net Regression MAE:\", mean_absolute_error(y_train, elastic_net_train_pred))\n",
    "\n",
    "print(\"Linear Regression R2 Score:\", r2_score(y_train, linear_train_pred))\n",
    "print(\"Lasso Regression R2 Score:\", r2_score(y_train, lasso_train_pred))\n",
    "print(\"Ridge Regression R2 Score:\", r2_score(y_train, ridge_train_pred))\n",
    "print(\"Elastic Net Regression R2 Score:\", r2_score(y_train, elastic_net_train_pred))\n",
    "\n",
    "# Predictions\n",
    "linear_test_pred = linear_grid.predict(X_test)\n",
    "lasso_test_pred = lasso_grid.predict(X_test)\n",
    "ridge_test_pred = ridge_grid.predict(X_test)\n",
    "elastic_net_test_pred = elastic_net_grid.predict(X_test)\n",
    "\n",
    "# Test evaluation\n",
    "print(\"\\nTest Evaluation Metrics:\")\n",
    "print(\"Linear Regression MAE:\", mean_absolute_error(y_test, linear_test_pred))\n",
    "print(\"Lasso Regression MAE:\", mean_absolute_error(y_test, lasso_test_pred))\n",
    "print(\"Ridge Regression MAE:\", mean_absolute_error(y_test, ridge_test_pred))\n",
    "print(\"Elastic Net Regression MAE:\", mean_absolute_error(y_test, elastic_net_test_pred))\n",
    "\n",
    "print(\"Linear Regression R2 Score:\", r2_score(y_test, linear_test_pred))\n",
    "print(\"Lasso Regression R2 Score:\", r2_score(y_test, lasso_test_pred))\n",
    "print(\"Ridge Regression R2 Score:\", r2_score(y_test, ridge_test_pred))\n",
    "print(\"Elastic Net Regression R2 Score:\", r2_score(y_test, elastic_net_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2182409303203.3074\n"
     ]
    }
   ],
   "source": [
    "# Create the Decision Tree Regressor model\n",
    "decision_tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "decision_tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = decision_tree_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score for training set: 0.9461844221614641\n",
      "Mean Absolute Error (MAE) for training set: 192858.55262278527\n",
      "Mean Squared Error (MSE) for training set: 294251475647.93646\n",
      "\n",
      "R^2 score for testing set: 0.5389993050904471\n",
      "Mean Absolute Error (MAE) for testing set: 450536.02430661605\n",
      "Mean Squared Error (MSE) for testing set: 2182409303203.3074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate R^2 score for training set\n",
    "y_train_pred = decision_tree_regressor.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(\"R^2 score for training set:\", r2_train)\n",
    "\n",
    "# Calculate other metrics for training set\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "print(\"Mean Absolute Error (MAE) for training set:\", mae_train)\n",
    "print(\"Mean Squared Error (MSE) for training set:\", mse_train)\n",
    "\n",
    "# Calculate R^2 score for testing set\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(\"\\nR^2 score for testing set:\", r2_test)\n",
    "\n",
    "# Calculate other metrics for testing set\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE) for testing set:\", mae_test)\n",
    "print(\"Mean Squared Error (MSE) for testing set:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check correlation, scatterplot,  pair plot, can we convert to linearity\n",
    "if records less than 10/20, can we mark to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
